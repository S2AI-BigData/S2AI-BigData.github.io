<!DOCTYPE HTML>
<!--
	Helios by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>S2AI-BigData</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="homepage is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<div id="header"  style="justify-content: center;text-align: center;">

					<!-- Inner -->
						<!-- <div class="inner"> -->
							<!-- <header> -->
								<!-- <h1><a href="index.html" id="logo">IEEE BigData 2022 Workshop on Knowledge Discovery and Data Mining in IT Operations (BigData-IT) </a></h1> -->
								
									<div class="col-md-12">
								
<h1>Workshop on Secure and Safe AI Agents for Big Data Infrastructures</h1> 
</div>
<br>
<div class="col-md-6" style="position: relative;
z-index: 10; ">
	<h3 style="color: white;"> Virtual co-located with <a target="_blank" rel="noopener noreferrer" class="conflink" href="https://conferences.cis.um.edu.mo/ieeebigdata2025/"><u>IEEE BigData 2025</u></a> </h3>
</div>
<!-- </div> -->
							<!-- </header> -->
							
						<!-- </div> -->

					<!-- Nav -->
						<nav id="nav">
							<div style="display:flex; margin-left: 20px;">
    <a href="index.html" style="text-decoration: none; font-size: 20px; font-weight: bold; color: white;">
        S2AI@BigData2025
    </a></div>
							<ul>
								
								<li><a href="index.html">Home</a></li>
								<li><a href="index.html#dates">Dates</a></li>
								<li><a href="cfp.html">CFP</a></li>
								<li><a href="key.html">Keynote</a></li>
								<li><a href="org.html">Organization Committee</a></li>
							</ul>
						</nav>

				</div>

			<!-- Main -->
				<div class="wrapper style2">

					<article id="about" class="container">
						<header>
							<h2>Introduction</h2>
							</header>
						<p style="font-size: 18px;">
							With the recent advancement in LLMs and foundation models, AI agents have gained popularity in a wide range of sectors such as education, finance, healthcare, research, transportation, and beyond. These agentic systems could consist of multiple LLM-based agents, tools, memory and storage to effectively solve complex tasks. However, as AI Agents become more embedded in complex environments and big data infrastructures, new challenges arise that need careful attention. Among the most pressing concerns is the need to prioritize AI agents to be more secure, explainable, and resilient. 
						</p >
						<p id="more" style="display: block; font-size: 18px;">
							The increasing number of AI agents and their integration with external tools and third-party applications significantly expand the attack surfaces within big data infrastructures. Each new connection or integration represents a possible vulnerability that can be exploited by adversaries to manipulate, gain unauthorized access to agents or sensitive data. During the data handling process by the AI agents, there arises a need to ensure compliance with regulatory frameworks in order to meet the standards for data privacy and transparency. 
						</p>
						<p style="font-size: 18px;">
							Further, as AI agents interact with big data infrastructure systems to perform tasks in an autonomous or semi-autonomous fashion, it is critical to understand their actions to increase user trust and enable intervention to prevent harmful actions. For example, trace data generated by agents could be mined to help explain their behavior, including why they took certain decisions or failed to complete a task successfully. But, how to generate and interpret trace data to ensure faithfulness and accountability of agent actions remains an open question. This challenge is further exacerbated in big data environments because Volume, Verocity, Variety, and Veracity make it much harder to both record and interpret traces. 
						</p>	
						<p style="font-size: 18px;">
							In addition, AI agents should also be robust to failures in dynamic big data systems. These systems often consist of multiple components such as AI agents, infrastructure elements and data sources, all of which can introduce various forms of noise, failures, and faults. Such issues may lead to cascading errors throughout the system. Therefore, AI agents must be designed to be resilient to handle these challenges and perform tasks reliably. 
						</p>
						<p style="font-size: 18px;">	
							Toward solving all these challenges, the goal of this workshop is to invite researchers and practitioners from the big data community to exchange ideas and develop algorithms, practical tools, and frameworks that aid in developing secure and safe AI agents for big data infrastructure.  
						</p>
					<!-- 	<footer>
							<a onclick="showMore()" id="moreBut" class="button">Show More</a>
						</footer> -->
					</article>

				</div>


<div class="wrapper style2">

					<article id="dates" class="container">
						<header>


							<h2>Important Dates</h2>
						</header>
						<p style="font-size: 18px;">
							<ul>
								<li style="font-size: 18px;"><b>Oct 24, 2025</b>: Abstract submission deadline</li>
								<li style="font-size: 18px;"><b>Oct 31, 2025</b>: Paper submission deadline</li>
<li style="font-size: 18px;"><b>Nov 7, 2025</b>: Notification of paper acceptance to authors</li>
<li style="font-size: 18px;"><b>Nov 23, 2025</b>: Camera-ready of accepted papers</li>
						<li style="font-size: 18px;"><b>Dec 8 - 11, 2025</b>: Workshops</li>
					</ul>

						</p>
					</article>
				</div>

<!--
<div class="wrapper style2">

					<article id="references" class="container">
<header>
							<h2>References</h2>
							</header>

<ol style="list-style-type:none;">
<li id="ref1">  [1] S. Jha, R. Arora, Y. Watanabe, T. Yanagawa, Y. Chen, J. Clark, B. Bhavya, M. Verma, H. Kumar, H. Kitahara, et al., “ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks,” *arXiv preprint arXiv:2502.05352*, 2025.
<li id="ref2"> [2] Z. Deng, Y. Guo, C. Han, W. Ma, J. Xiong, S. Wen, and Y. Xiang, “AI agents under threat: A survey of key security challenges and future pathways,” *ACM Computing Surveys*, vol. 57, no. 7, pp. 1–36, 2025. </li>
<li id="ref3"> [3] M. Cemri, M. Z. Pan, S. Yang, L. A. Agrawal, B. Chopra, R. Tiwari, K. Keutzer, A. Parameswaran, D. Klein, K. Ramchandran, et al., “Why do multi-agent LLM systems fail?,” *arXiv e-prints*, arXiv:2503, 2025.</li>
<li id="ref4"> [4] D. Deshpande, V. Gangal, H. Mehta, J. Krishnan, A. Kannappan, and R. Qian, “TRAIL: Trace Reasoning and Agentic Issue Localization,” *arXiv preprint arXiv:2505.08638*, 2025. </li>
<li id="ref5"> [5] B. Li, K. Mellou, B. Zhang, J. Pathuri, and I. Menache, “Large language models for supply chain optimization,” *arXiv preprint arXiv:2307.03875*, 2023. </li>
<li id="ref6"> [6] X. Liu, J. Zheng, G. Yang, S. Wen, and Q. Liu, “Improving the context length and efficiency of code retrieval for tracing security vulnerability fixes,” *arXiv preprint arXiv:2503.22935*, 2025. </li>
<li id="ref7"> [7] Y. Surampudi, “Big data meets LLMs: A new era of incident monitoring,” *Libertatem Media Private Limited*, 2024.
<li id="ref8"> [8] X. Li, S. Wang, S. Zeng, Y. Wu, and Y. Yang, “A survey on LLM-based multi-agent systems: workflow, infrastructure, and challenges,” *Vicinagearth*, vol. 1, no. 1, p. 9, 2024. </li>
<li id="ref9"> [9] M. Chacon-Chamorro, L. F. Giraldo, N. Quijano, V. Vargas-Panesso, C. Gonza ́lez, J. S. Pinzo ́n, R. Manrique, M. R ́ıos, Y. Fonseca, D. Go ́mez-Barrera, and M. Perdomo-Pe ́rez, “Cooperative resilience in artificial intelligence multiagent systems,” *IEEE Transactions on Artificial Intelligence*, 2025. </li>
<li id="ref10">[10] J. Owotogbe, “Assessing and enhancing the robustness of LLM-based multi-agent systems through chaos engineering,” *arXiv preprint arXiv:2505.03096*, 2025.</li>
<li id="ref11"> [11] P. Y. Zhong, S. Chen, R. Wang, M. McCall, B. L. Titzer, H. Miller, and P. B. Gibbons, “Rtbas: Defending LLM agents against prompt injection and privacy leakage,” *arXiv preprint arXiv:2502.08966*, 2025. </li>
<li id="ref12"> [12] A.Li,Y.Zhou,V.C.Raghuram,T.Goldstein,andM.Goldblum,“Commercial LLM agents are already vulnerable to simple yet dangerous attacks,” *arXiv preprint arXiv:2502.08586*, 2025. </li>
<li id="ref13"> [13] T. Rebedea, R. Dinu, M. Sreedhar, C. Parisien, and J. Cohen, “Nemo Guardrails: A toolkit for controllable and safe LLM applications with programmable rails,” *arXiv preprint arXiv:2310.10501*, 2023. </li>
<li id="ref14"> [14] S. S. L. Chukkapalli, A. Joshi, T. Finin, and R. F. Erbacher, “CAPD: A context-aware, policy-driven framework for secure and resilient IoBT operations,” * SPIE, Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications IV, vol. 12113, pp. 224–232*, 2022. </li>
</article>
</div>
-->
<div class="copyright">
										<ul class="menu">
											<li></li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
										</ul>
									</div>
		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>






